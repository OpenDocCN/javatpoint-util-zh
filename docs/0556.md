# TCP 和 UDP 负载平衡

> 原文：<https://www.javatpoint.com/nginx-tcp-and-udp-load-balancing>

Nginx Plus 可以代理和负载均衡 **TCP(传输控制协议)**流量。TCP 是许多流行应用程序和服务的协议，例如 MySQL、LDAP 和 RTMP。

同样，Nginx Plus 可以代理和负载平衡 UDP 流量。用户数据报协议是许多流行的非事务性应用程序的协议，如域名系统、系统日志和 RADIUS。

## 配置反向代理

首先，我们需要配置反向代理，以便 Nginx 开源或 Nginx Plus 可以将 TCP 连接或 UDP 数据报从客户端转发到上游组或代理服务器。

使用 Nginx 配置文件并执行以下步骤:

1.创建顶级流{ }块。

```

stream {
    # ...
}

```

2.为顶级**流{**上下文中的每个虚拟服务器定义一个或多个服务器{ }配置块。

3.在服务器{ }配置块中，包含每台服务器的侦听指令，以定义服务器侦听的 IP 地址和/或端口。

对于 UDP 流量，还要添加 **UDP** 参数。由于 TCP 是流上下文的默认协议，因此没有 TCP 参数侦听指令:

```

stream {

    server {
        listen 12345;
        # ...
    }

    server {
        listen 53 udp;
        # ...
    }
    # ...
}

```

4.添加代理传递指令，以定义代理服务器或服务器将流量转发到的上游组:

```

stream {

    server {
        listen     12345;
        # traffic of TCP will be forwarded to the "stream_backend" upstream group
        proxy_pass stream_backend;
    }

    server {
        listen     12346;
        #traffic of TCP will be forwarded to the specified server
        proxy_pass backend.example.com:12346;
    }

    server {
        listen     53 udp;
        #traffic of UDP will be forwarded to the "dns_servers" upstream group
        proxy_pass dns_servers;
    }
    # ...
}

```

5.如果代理服务器有许多不同的网络接口，您可以选择将 Nginx 配置为在连接到上游服务器时使用特定的源 IP 地址。

添加 proxy_bind 指令和相应网络接口的 IP 地址。

```

stream {
    # ...
    server {
        listen     127.0.0.1:12345;
        proxy_pass backend.example.com:12345;
        proxy_bind 127.0.0.1:12345;
    }
}

```

6.可选地，我们可以调整两个内存缓冲区的大小，nginx 可以在其中放置来自客户端和上游连接的数据。如果有少量数据，可以减少缓冲区，这可能会节省内存资源。

如果有大量数据，可以增加缓冲区的大小，以减少套接字读写操作的数量。一旦在一个连接上接收到数据，Nginx 就会读取数据并通过另一个连接转发。要控制缓冲区，请使用 proxy_buffer_size 指令:

```

stream {
    # ...
    server {
        listen            127.0.0.1:12345;
        proxy_pass        backend.example.com:12345;
        proxy_buffer_size 16k;
    }
}

```

* * *

## 配置 TCP 或 UDP 负载平衡

要配置 TCP 或 UDP 负载平衡，请执行以下操作:

1.首先，创建一组服务器或上游组，其流量将得到负载平衡。在顶级流{ }上下文中定义一个或多个上游{ }的配置块，并设置上游组的名称，例如，TCP 服务器的**流 _ 后端**，UDP 服务器的**DNS _ 服务器**:

```

stream {

    upstream stream_backend {
        # ...
    }

    upstream dns_servers {
        # ...
    }

    # ...
}

```

2.用上游服务器填充上游组。在上游块中，包括每个上游服务器的服务器指令，指定其主机名或 IP 地址以及强制端口号。

```

stream {

    upstream stream_backend {
        server backend1.example.com:12345;
        server backend2.example.com:12345;
        server backend3.example.com:12346;
        # ...
    }

    upstream dns_servers {
        server 192.168.136.130:53;
        server 192.168.136.131:53;
        # ...
    }

    # ...
}

```

3.配置上游组使用的负载平衡方法。我们可以使用以下方法之一:

**循环调度:** Nginx 默认使用循环调度算法进行流量负载均衡，将流量按顺序定向到配置的上游组中的服务器。因为循环是默认方法，所以没有针对它的指令。

只需在顶级流{}上下文中创建一个上游{ }配置块，并包含服务器指令。

**最少连接数:** Nginx 选择当前活动连接数最少的服务器。

**最短时间:**此方法仅适用于 Nginx Plus。Nginx 选择平均延迟最低、活动连接数最少的服务器。参数有:

*   连接-连接到上游服务器的时间
*   first_byte -接收数据的第一个字节的时间
*   last_byte -从服务器接收完整响应的时间。

```

upstream stream_backend {
    least_time first_byte;
    server backend1.example.com:12345;
    server backend2.example.com:12345;
    server backend3.example.com:12346;
}

```

**Hash:** 基于用户定义的密钥 Nginx 选择服务器，例如源 IP 地址($remote_addr)。

```

upstream stream_backend {
    hash $remote_addr;
    server backend1.example.com:12345;
    server backend2.example.com:12345;
    server backend3.example.com:12346;
}

```

**随机:**在这种情况下，每个连接都被传递给随机选择的服务器。如果参数**二**被指定，那么首先 Nginx 考虑服务器权重随机选择两个服务器，然后使用指定的服务器选择这些服务器之一。

*   最少连接-活动连接的最少数量。
*   最小时间=标头-从服务器接收响应标头的最小平均时间。
*   最短时间=最后一个字节-从服务器接收完整响应的最短平均时间。

```

upstream stream_backend {
    random two least_time=last_byte;
    server backend1.example.com:12345;
    server backend2.example.com:12345;
    server backend3.example.com:12346;
    server backend4.example.com:12346;
}

```

4.或者，为每个上游服务器定义特定于服务器的参数，包括最大连接数、服务器重量等:

```

upstream stream_backend {
    hash   $remote_addr consistent;
    server backend1.example.com:12345 weight=5;
    server backend2.example.com:12345;
    server backend3.example.com:12346 max_conns=3;
}
upstream dns_servers {
    least_conn;
    server 192.168.136.130:53;
    server 192.168.136.131:53;
    # ...
}

```

### TCP 和 UDP 负载平衡配置示例

让我们看一个 TCP 和 UDP 负载平衡配置的例子:

```

stream {
    upstream stream_backend {
        least_conn;
        server backend1.example.com:12345 weight=5;
        server backend2.example.com:12345 max_fails=2 fail_timeout=30s;
        server backend3.example.com:12345 max_conns=3;
    }

    upstream dns_servers {
        least_conn;
        server 192.168.136.130:53;
        server 192.168.136.131:53;
        server 192.168.136.132:53;
    }

    server {
        listen        12345;
        proxy_pass    stream_backend;
        proxy_timeout 3s;
        proxy_connect_timeout 1s;
    }

    server {
        listen     53 udp;
        proxy_pass dns_servers;
    }

    server {
        listen     12346;
        proxy_pass backend4.example.com:12346;
    }
}

```

在上面的示例中，所有与 TCP 和 UDP 代理相关的功能都是在流的块中配置的。

有两个名为 upstream 的块，每个块包含三个彼此托管相同内容的服务器。在**服务器**中，对于每台服务器，服务器名称后面是强制端口号。连接根据最少连接负载平衡方法分布在所有服务器中:连接到达活动连接数量较少的服务器。

* * *