# Linux 内存管理

> 原文:[https://www.javatpoint.com/linux-memory-management](https://www.javatpoint.com/linux-memory-management)

Linux 内存管理子系统负责管理系统内部的内存。它包含实现 ***按需分页*** 和 ***的虚拟内存。***

此外，它还包含用户空间程序和内核内部结构的内存分配。Linux 内存管理子系统包括映射到进程地址空间的文件和其他一些东西。

Linux 内存管理子系统是一个具有多种可配置设置的复杂系统。几乎每个设置都可以通过/proc 文件系统获得，并且可以通过 sysctl 进行调整和获取。这些类型的应用编程接口在/proc/sys/vm/的 ***man 5 proc*** 和 ***文档中指定。***

Linux 内存管理包括它的行话。这里我们详细讨论如何理解 Linux 内存管理的几种机制。

## 概念概述

Linux 内存管理是一个复杂的系统，通过无内存管理单元的微控制器到超级计算机，它包含了许多支持各种系统的功能。

对于系统来说，没有*的内存管理被称为***【nommu】***，它获得了一个专用的文档，最终有望被写入。然而，有几个概念是相似的。*

 *这里，我们将假设内存管理单元存在，并且中央处理器可以将任何虚拟地址转换为物理地址。

![Linux Memory Management](../Images/3d0e2c61013161052570cc68748c2240.png)

*   巨大的页面
*   虚拟记忆入门
*   区域
*   页面缓存
*   节点
*   匿名记忆
*   OOM 杀手
*   压紧
*   改造

### 巨大的页面

地址转换需要各种存储器访问。与中央处理器的速度相比，这些内存访问非常慢。为了忽略处理器在地址翻译上花费的宝贵周期，中央处理器管理这些类型翻译的缓存，称为 ***翻译后备缓冲器(TLB)。*T3】**

### 虚拟记忆入门

在计算机系统中，物理内存是一种受限资源。物理内存不一定是连续的。它可以作为一组不同范围的地址来访问。此外，CPU 的不同架构和类似架构的实现对于如何指定这些类型的范围有不同的观点。

这将使直接处理物理内存变得相当困难，为了忽略这种复杂性，指定了一种机制虚拟内存。

虚拟内存通过应用软件分离物理内存细节。

它只允许在物理内存中保留所需的细节。它提供了一种在进程间共享和保护受控数据的机制。

### 区域

Linux 根据可能的使用情况将内存页面组合成一些区域。假设 ***ZONE_HIGHMEM*** 将包括未永久映射到内核地址空间的内存，**T5】ZONE _ DMA**将包括可由各种设备用于 DMA 的内存，**T9】ZONE _ NORMAL**将包括正常寻址的页面。

### 页面缓存

将数据放入内存的常见情况是通过文件读取数据，因为物理内存不稳定。

数据将被放在页面缓存中，以便在读取任何文件时忽略后续读取时对磁盘的昂贵访问。

类似地，无论何时写入任何文件，数据都将位于页面缓存中，并进入后备存储设备。

### 节点

几台多处理器机器可以定义为 ***NUMA -非均匀内存访问*** 系统。存储器被组织成*存储体，这些存储体包括依赖于通过这些类型系统中的处理器的 ***【距离】*** 的不同访问延迟。所有的存储体都被称为一个 ***节点*** ，对于所有的节点，Linux 都创建了一个独立的内存管理子系统。单个节点包含其 ***区域*** 集合、已用页面和空闲页面列表以及多个统计计数器。*

 *### 匿名记忆

匿名映射或匿名内存指定不被任何文件系统支持的内存。这些类型的映射是为程序的堆和栈隐式开发的，或者是通过显式调用 ***mmap(2)系统调用开发的。*T3】**

匿名映射通常只指定允许程序访问的虚拟内存区域。

### OOM 杀手

内核可能无法回收足够的内存，加载的机器内存将被耗尽，无法继续实现。

### 压紧

当系统执行时，各种任务分配释放的内存空间，并将其分区。但是，可以用虚拟内存限制分散的物理页面。内存压缩定义了 ***分区*** 的问题。

### 改造

根据页面的使用情况，Linux 内存管理对它的处理是不同的。由于缓存了硬盘上其他地方存在的详细信息或者由于可以再次换出到硬盘上而被释放的页面被称为**可回收页面。**

## CMA 调试接口

它有助于从 CMA 的不同区域中检索基本细节，并测试所有区域中的发布/分配。

所有的 CMA 区域都在 <debugfs>/CMA/上指定了一个目录，该目录通过内核的 CMA 索引进行索引。因此，初始 CMA 区域将是:</debugfs>

```
/cma/cma-0 
```

基于该目录的文件结构如下:

*   **【RO】base _ pfn:**分区的基地 ***页面格式号*** (或 pfn)。
*   **【RO】order _ per _ bit:**由单个位指定的页面序列。
*   **【RO】计数:**CMA 区域内的内存量。
*   **【RO】位图:**分区内部的页面位图。
*   **【WO】alloc:**从 CMA 区域分配 N 页。例如:

```

echo 5 > /cma/cma-2/alloc 
```

## 超大页面

### 介绍

这个文件的目的是对 Linux 内核中的 hugetlbpage 支持做一个简短的概述。这种类型的支持是在大多数最新架构所提供的多种页面大小支持的基础上创建的。

假设，x86 CPUs 支持 2M 和 4K 页面大小正常情况下，ia64 架构提供支持超过一页大小 256M、16M、4M、1M、256K、64K、8K、4K，ppc64 提供支持 16M 和 4K。

TLB 可以定义为虚拟到物理的转换缓存。它通常是处理器上非常稀缺的资源。

各种操作系统都试图最大限度地利用有限的 TLB 资源。

现在，这种优化更加复杂，因为几个千兆字节(物理内存)更容易存在。

用户可以通过应用经典的 SYSV 共享内存系统调用(shmat 和 shmget)或 mmap 系统调用来使用 Linux 内核中巨大页面的支持。

最初，Linux 内核需要用一个文件创建，即***CONFIG _ hugetbfs***和***CONFIG _ HUGETLB _ PAGE***配置选项。

文件，即 ***/proc/meminfo*** 给出了内核巨大页面池中持久 hugetlb 页面总数的详细信息。

此外，它显示了巨大的页面大小(默认)和剩余巨大页面数量的详细信息，在默认大小的巨大页面池中保留和空闲。

需要巨大页面的大小来为系统调用生成参数的精确大小和对齐，这将有助于映射巨大页面的区域。

***/proc/sys/VM/NR _ hugepages***文件代表内核巨大页面池中 ***【持久化】*** 巨大页面(当前)的计数。

***【持久】*** 如果通过任务释放，巨大的页面将返回巨大页面池。动态地，具有许多根权限的用户可以通过减少或增加 ***nr_hugepages*** 值来分配或释放一些持久的巨大页面。

巨大页面使用的页面可以保留在内核中，不能用于其他目的。巨大的页面无法在内存压力下换出。

## 空闲页面跟踪

### 动机

该特性允许跟踪通过工作负载访问哪个内存页面。

这些信息有助于估计工作负载的工作集大小，如果配置工作负载的参数、确定工作负载的位置或设置计算机群集中内存组的限制，则可以考虑这些信息。

可以通过使用来启用它

```

CONFIG_IDLE_PAGE_TRACKING=y.

```

### 用户接口

空闲页面跟踪的 API 在***/sys/kernel/mm/page _ idle***找到。目前结合了***/sys/kernel/mm/page _ idle/位图*** 和读写文件。

该文件操作一个位图，其中所有位都对应于内存页面。该位图由 8 字节整数数组定义，PFN #i 上的页面将被映射到#i/64 数组元素的#i %64 位(字节序列是本机的)。如果该位是固定的，则相关页面是空闲的。

### 实施细节

在内部，内核保留对用户内存页面的访问记录，以便在内存不足的情况下回收未引用的页面。当一个页面最近被一个进程的地址空间访问时，它将被检查引用。如果出现以下情况，就会出现后一种情况:

*   通过系统调用 ***(例如，读取(3)或写入(3))*** 进行用户空间写入或读取的过程
*   借助 ***get_user_pages()*** 可以通过设备驱动程序访问页面
*   用于搅动文件系统缓冲区的页面由于需要存储在其中的文件系统元数据的过程而被写入或读取 ***(例如，列出目录树)***

## 内核相同页面合并

内核同一个页面合并(或***【KSM】***)是一个重复数据删除节省内存的方面。它是由包含在 ***2.6.32*** 中的**CONFIG _ KSM = y、** 启用到 Linux 内核的。

最初，KSM 被指定与 KSM(其中称为 ***【内核共享内存】*** )一起使用，通过共享它们之间的公共信息来将其他虚拟机装入物理内存。

但是，对于生成几个类似数据实例的应用程序来说，这可能会有所帮助。

KSM 的 ksmd 守护程序定期扫描向其注册的用户内存区域，检查是否有相同的内容页可以被单独的写保护页替代(当任何进程希望更新其内容时自动复制)。

KSM 守护程序在单个通道内扫描的页面数量以及通道之间的时间可以在 sysfs 接口的帮助下配置。

内核 samepage 合并只合并 ***私有(匿名)*** 页面，从不合并文件(页面缓存)页面。最初，KSM 的合并页面被锁定在内核的内存中，但现在可以像换另一个用户页面一样换出。

### 用马达控制 KSM

KSM 仅在应用程序建议可能在 mad vice(2)系统调用的帮助下合并的那些地址空间区域上实现:

```

int madvise(addr, length, MADV_MERGEABLE)

```

然后，应用程序可能会调用:

```

int madvise(addr, length, MADV_UNMERGEABLE)

```

#### 注意:这个调用(取消镜像)可能突然需要额外的内存，并且可能无法使用 EAGAIN。

### KSM 守护进程 sysfs 接口

KSM 的守护进程由***/sys/kernel/mm/KSM/***文件中的 sysfs 文件管理，每个文件都可以读取，但只能由 root 用户写入:

### 页面到扫描

它决定了在 ksmd 守护程序进入睡眠状态之前，扫描过程需要多少页。

**例如**

```

echo 100 > /sys/kernel/mm/ksm/pages_to_scan.

```

#### 注意:默认情况下，示范目标选择 100。

### 睡眠 _ 毫秒

它确定 ksmd 守护程序在下一次扫描之前必须休眠多少毫秒。

**例如**

```

echo 20 > /sys/kernel/mm/ksm/sleep_millisecs 

```

#### 注:演示目标默认选择 20。

### 奔跑

它将设置为 0，用于停止 ksmd 守护程序执行，但继续合并页面，

对于运行 ksmd 守护程序，它将设置为 1，

```

echo 1 > /sys/kernel/mm/ksm/run

```

它将设置为 2，用于停止 ksmd 守护程序，并取消当前合并的每个页面的合并，但保留为下一次运行注册的可合并位置。

### max_page_sharing

所有 KSM 页面允许的最大共享。它强制执行复制限制，以避免虚拟内存各种操作的高延迟。它涉及分发 KSM 页面的虚拟映射遍历。

最小值为 2，因为新制作的 KSM 页面至少有两个共享者。减少这种遍历定义了在页面迁移、NUMA 平衡、压缩和交换时，虚拟内存的各种操作会有更大的延迟。

### 稳定 _ 节点 _ 链 _ 修剪 _ 毫秒

它描述了 KSM 检查页面元数据的频率，这些元数据达到了陈旧细节的复制极限。较小毫秒的值将使用较低的延迟释放 KSM 的元数据。

但是，它们会使 ksmd 守护程序在扫描时使用更多的 CPU。当 KSM 的单个页面还没有遇到 max_page_sharing 时，这是一个 noop。

MADV 可合并和 KSM 的有效性显示在:

```

/sys/kernel/mm/ksm/:

```

### 页面 _ 共享

它定义了使用了多少页面(共享的)。

### 页面共享

它定义了有多少其他站点在分发它们，即存储了多少。

### 页面 _ 未共享

它定义了多少页面是特定的，但被反复检查以合并。

### 全扫描

它定义了每个可合并区域被扫描的次数。

### 页面 _ 易失性

它定义了在一棵树中有多少页面修改得非常快。

### 稳定的节点链

它定义了遇到限制的 KSM 页码，即 ***max_page_sharing。*T3】**

### 稳定节点

它定义了 KSM 页数(重复的)。

高比例的 ***页面 _ 共享*** 和 ***页面 _ 共享*** 代表更好的共享。此外， ***页面共享*** 和 ***页面共享*** 的高比例代表浪费的尝试。

***pages_volatile*** 掌握不同类型的活动。然而，高比率也将代表 MADV 的不良使用。

***pages _ sharing/pages _ shared***的最大可能比例通过***max _ pages _ sharing***可调来限制。对于增加比例***max _ page _ sharing***应相应增加。

## 内存热插拔

本文档描述了内存热插拔，包括其当前状态以及如何使用。这个文本内容会经常改变，因为仍在开发内存热插拔。

介绍

### 记忆热插拔目标

内存热插拔允许用户不断减少内存量。通常有两个目标:

**(1)** 改变记忆量。它是允许一个方面，如需求的能力。

**(2)** 物理安装或移除 NUMA 节点或内存。它用于交换 NUMA 节点/内存并降低功耗。

第一个目标是通过高度虚拟化的平台实现的，第二个目标是通过硬件实现的。另外，第二个目标支持内存的电源管理。

Linux 中的内存热插拔是为这两个目标而开发的。

### 内存热插拔阶段

在内存热插拔中，主要有两个阶段:

*   内存热插拔的物理阶段
*   内存热插拔的逻辑阶段

物理阶段用于通信固件或硬件，并为热插拔内存擦除或搭建平台。这一阶段对于 **(2)** 目标至关重要，但也是在高度虚拟化的平台之间进行沟通的好阶段。

内核将识别新的内存，为内存管理创建新的表，并在内存热插拔时为新内存的操作创建 sysfs 文件。

如果固件支持通知操作系统有新的内存连接。这个阶段是自动触发的。ACPI 可以警惕这一事件。在这种情况下，它不会提醒此事件，而是由系统管理员使用称为“探测”的操作。

逻辑阶段用于将状态更改为用户不可用或可用。用户视图的内存量由该阶段修改。当有一定范围的内存可用时，内核会启用内存中的每个内存作为空闲页面。

此阶段在本文档中定义为*线上/线下。*

 *系统管理员编写的 sysfs 文件遇到了逻辑阶段。对于热添加情况，应在物理阶段后手动运行。

### 内存在线/离线任务单元

内存热插拔应用了 ***SPARSEMEM*** 内存模型，该模型允许将内存分类为大小相似的各种 ***块*** 。这类组块被称为 ***“段”。*** 一个内存段的大小是 ***架构相关的。***

内存段与被称为“内存块”的**块**相关联 ***。*** 内存块大小说明了逻辑单元，内存在线/离线操作将在该逻辑单元下实现。它也是 ***架构依赖的。***

除非体系结构另有说明，否则内存块的默认大小与内存部分的大小相同。

要确定内存块大小，请考虑以下文件:

```

/sys/devices/system/memory/block_size_bytes

```

## 内核的配置

内核应该使用以下配置选项进行编译，以便使用内存热插拔功能:

### 对于每个内存热插拔:

*   内存热添加许可
*   内存(CONFIG_SPARSEMEM)
*   内存模型->稀疏

### 此外，以下是启用内存移除所必需的:

*   页面迁移(配置迁移)
*   允许内存热删除

### 还有，以下是 ACPI 记忆火锅必备的:

*   该选项可以是内核模块。
*   内存热插拔(在 ACPI 的支持菜单上)

作为相应的配置，当我们的盒子包含 ACPI 的 NUMA 节点热插拔功能时，那么这个选项也是必要的。

*   PNP0A06、PNP0A05 和 ACPI0004 容器驱动程序(配置 _ ACPI _ 容器)(在 ACPI 的支持菜单上)。
*   该选项也可以是内核模块。

## 内存热插拔 sysfs 文件

每个内存块在 sysfs 文件中都有其设备详细信息。所有内存块的指定如下:

```

/sys/devices/system/memory/memoryXXX

```

其中存储块的 id 是 ***XXX。*T3】**

假设每个内存段都在此范围内，并且对于通过 sysfs 目录覆盖的那些内存块，此范围内不存在内存漏洞。

目前没有办法确定是否有任何内存漏洞。但是，一个内存孔的存在不应影响内存块热插拔兼容性。

例如，假设内存块大小为 1gb。从 0x100000000 开始的任何内存的设备将是

```

/sys/devices/system/memory/memory4:

```

```

(0*100000000 / 1GiB = 4)

```

该装置将覆盖 ***(0*100000000...0*140000000)*** 地址范围

我们可以在所有内存块下看到五个文件:

```

/sys/devices/system/memory/memory XXX/phys_index
/sys/devices/system/memory/memory XXX/phys_device
/sys/devices/system/memory/memory XXX/state
/sys/devices/system/memory/memory XXX/removable
/sys/devices/system/memory/memory XXX/valid_zones

```

## 无内存管理单元支持内存支持

内核包括对非内存管理单元情况下内存映射的有限支持。从用户空间的角度来看，内存映射与 mmap()系统调用、execve()系统调用和 shmat()调用一起使用。

从内核的角度来看，execve 映射是通过 binfmt 驱动程序执行的。它调用 mmap()的例程来执行原始工作。

此外，内存映射的行为与 ptrace()、clone()、vfork()和 fork()的工作方式相关联。在 uClinux 下没有克隆()和分叉()应该提供一个 CLONE_VM 标志。

无 MMU 和 MMU 情况下的行为相同，但不完全相同。此外，它在字母条件方面受到更多限制。

### 1.匿名映射，

### 地图 _ 私人

*   虚拟机区域由随机页面**支持(在内存管理单元的情况下)。**
*   虚拟机区域由页面的随机连续执行支持**(在没有内存管理单元的情况下)。**

### 2.匿名映射，

### 地图 _ 共享

它的工作原理非常像私有映射。除此之外，在 MMU 的情况下，它们是围绕 clone()和 fork()共享的，而没有 CLONE_VM。因为该行为对于 MAP_PRIVATE 是可互换的，并且非 MMU 的情况不支持这些行为。

### 3.文件，！PROT 写，PROT 读/PROT 执行，地图私人

*   虚拟机区域由从文件**(对于内存管理单元)**中读取的页面支持。这些更改反映在到基础文件的映射中。
*   **在无 MMU 的情况下:**
*   当相似文件的相似部分包含兼容权限时，内核会重新使用现有的映射，即使它是由其他进程(如果有)创建的。
*   如果可能的话，当文件映射具有适当的映射保护能力和 NOMMU_MAP_DIRECT 能力时，文件映射将直接位于备份设备上。Mtd、cramfs、romfs 和 ramfs 可能都允许这样做。
*   文件写入不会影响映射，映射写入在其他进程中是可见的，但绝不能发生。

### 4.文件，PROT 写，PROT 读/PROT 执行，映射私人

*   **在 MMU 的情况下:**像非 PROT_WRITE 的情况一样工作。排除页面将在实际写入之前被复制。
*   **在没有 MMU 的情况下:**像非 PROT_WRITE 的情况一样工作。排除，副本将一直发生，永远不会被共享。

### 5.文件，PROT 读/PROT 执行/PROT 写，地图共享，文件/块开发

*   **在 MMU 的情况下:** VM 区域由通过文件读取的页面支持；反映到页面后备存储器中的文件写入；共用一个叉子。
*   **无 MMU 时:**不支持。

### 6.PROT 读/PROT 执行/PROT 写，映射共享，内存支持块开发

*   **在 MMU 的情况下:**至于常规文件(普通)。
*   **无 MMU 情况下:**至于各种内存备份的常规文件。但是，blockdev 可以在不调用缩写的情况下连续运行页面。此外，ramdisk 驱动程序可以在分配每个内存作为前面的连续阵列时做到这一点。

### 7.PROT 读/PROT 执行/PROT 写，映射共享，内存支持的常规文件

*   **在 MMU 的情况下:**至于常规文件(普通)。
*   **在没有 MMU 的情况下:**提供内存支持文件的文件系统(如 tmpfs 或 ramfs)可能会选择通过提供一个连续的页面序列来映射 mmap、截断、打开序列。
    在这种情况下，共享可写内存的映射是可能的。就像 MMU 的情况一样。
    当文件系统不提供这种支持时，映射请求将被拒绝。

### 8.PROT 读/PROT 执行/PROT 写，映射共享，内存支持的 chardev

*   **在 MMU 的情况下:**至于常规文件(普通)。
*   **在没有 MMU 的情况下:**字符设备驱动程序可能会选择通过在提供准内存或可直接访问的内存时直接访问底层设备来纪念 ***mmap()*** 。当驱动程序不提供这种支持时，映射请求将被拒绝。

## 无内存管理单元内存的进一步要点

*   私有映射请求可能会返回一个不与页面对齐的缓冲区。这是因为 XIP 可能会采取立场，数据可能不会在后备存储中分页对齐。
*   对于匿名映射，根据 Linux 的手册页，请求分配的内存通常会在备份之前由内核释放。
*   对于匿名映射，请求总是页面对齐的。请求大小必须是 2 的幂。
*   无 MMU 模式中的***/proc/<pid>/地图</pid>*** 可以检测到进程中使用的每个映射的列表。
*   无内存管理单元模式下的 ***/proc/maps*** 可以检测到系统上每个匿名映射和私有副本的列表。

* * ****